{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TECOCO_Lexer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BDlzGinYOL6R",
        "S-9bD6LZOR1B"
      ],
      "authorship_tag": "ABX9TyMtwGiZIe6arep/wS7O5IZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernanvilla/UNALTECOCO-2020-01/blob/master/Tecoco_Clase%2005_01_An%C3%A1lisis%20L%C3%A9xico%20C%C3%B3digo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlzGinYOL6R",
        "colab_type": "text"
      },
      "source": [
        "# La Clase Token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFmojg8vNyvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "class Token(object):\n",
        "    # Estructura simple de token\n",
        "    def __init__(self, type, val, pos):\n",
        "        # Constructor de la clase        \n",
        "        self.type = type\n",
        "        self.val = val\n",
        "        self.pos = pos\n",
        "    \n",
        "    def __str__(self):\n",
        "      #Método para mostrar strings, similar a ToString\n",
        "      return '%s | %s |-> en la posición: %s' % (self.type, self.val, self.pos)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-9bD6LZOR1B",
        "colab_type": "text"
      },
      "source": [
        "# La Clase LexerError"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4f1q8ciN0QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LexerError(Exception):\n",
        "    # Lanzador de Excepciones en el Lexer.         \n",
        "    def __init__(self, pos):\n",
        "        # Posición en la línea de entrada donde se generó el error\n",
        "        self.pos = pos"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAiRpOZQOfR3",
        "colab_type": "text"
      },
      "source": [
        "# La Clase Lexer, Lexer Simple basado en expresiones regulares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzwdbsQ5Pv3P",
        "colab_type": "text"
      },
      "source": [
        "El Contructor del Lexer tiene como parametros: \n",
        "* **`rules`**: Es un listado de reglas, cada regla es un par `regex, type`, donde `regex` es la expresión regular usada para reconocer un token y `type` es el tipo de token a retonar cuando este se ha reconocido.\n",
        "* **`skip_whitespace`**: Si es True, se omitiran los espacios en blanco (\\s+) y no serán analizados por el lexer. En caso de que sea False se deben especificar las reglas de cómo analizar los espacios en blanco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pGgzJoiOf0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lexer(object):\n",
        "    def __init__(self, rules, skip_whitespace=True):\n",
        "        idx = 1\n",
        "        regex_parts = [] #Lista\n",
        "        self.group_type = {} #Diccionario\n",
        "        # Las expresiones regulares se agrupan, GROUP1, GROUP2 y asi \n",
        "        # sucesivamente, para facilitar su análisis\n",
        "\n",
        "        for regex, type in rules:\n",
        "            groupname = 'GROUP%s' % idx\n",
        "            regex_parts.append('(?P<%s>%s)' % (groupname, regex))\n",
        "            print('Reconocido: (?P<%s>%s)' % (groupname, regex))\n",
        "            self.group_type[groupname] = type            \n",
        "            idx += 1\n",
        "\n",
        "        print(\"\\nGrupos Reconocidos: %s\" % self.group_type)\n",
        "        self.regex = re.compile('|'.join(regex_parts))\n",
        "        print(\"\\n Expresión Total: %s\\n\" % self.regex)\n",
        "        self.skip_whitespace = skip_whitespace\n",
        "        self.re_ws_skip = re.compile('\\S')\n",
        "\n",
        "    def input(self, buf):\n",
        "        # Inicializa el lexer con un buffer como entrada\n",
        "        # el cual es la línea de caracteres a analizar        \n",
        "        self.buf = buf\n",
        "        self.pos = 0\n",
        "\n",
        "    def token(self):\n",
        "        # Retorna el siguiente token encontrado en el buffer de entrada.\n",
        "        #    Cuando se alcanza el final del buffer se retorna None (null).\n",
        "        #    Se lanza una excepción si ocurre un error lexico, es decir, \n",
        "        #    la parte actual del buffer no coincide con ninguna regla.        \n",
        "      \n",
        "        if self.pos >= len(self.buf):\n",
        "            return None #Si ya se terminó la línea\n",
        "        else:\n",
        "            if self.skip_whitespace:\n",
        "                m = self.re_ws_skip.search(self.buf, self.pos)\n",
        "\n",
        "                if m:\n",
        "                    self.pos = m.start()\n",
        "                else:\n",
        "                    return None\n",
        "         \n",
        "            m = self.regex.match(self.buf, self.pos) #si alguna regla aplica\n",
        "            if m:\n",
        "                groupname = m.lastgroup\n",
        "                tok_type = self.group_type[groupname]\n",
        "                tok = Token(tok_type, m.group(groupname), self.pos)\n",
        "                self.pos = m.end()\n",
        "                return tok\n",
        "\n",
        "            raise LexerError(self.pos)\n",
        "\n",
        "    def tokens(self):\n",
        "        # Retorna un iterador para el token encontrado\n",
        "        while 1:\n",
        "            tok = self.token()\n",
        "            if tok is None: break\n",
        "            yield tok\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8B7bSzaQuis",
        "colab_type": "text"
      },
      "source": [
        "# Uso del Lexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJO3LkeQrI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "603a15f1-d43f-4611-e76b-cc344c896a3c"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    reglas = [        \n",
        "        ('[+-]?\\d+(\\.\\d+)?','NUMERODECIMAL'),\n",
        "        ('[+-]?\\d+',        'NUMEROENTERO'),\n",
        "        ('seno',            'FNSENO'),\n",
        "        ('[a-zA-Z_]\\w+',    'IDENTIFICADOR'),\n",
        "        ('\\+',              'MAS'),\n",
        "        ('\\-',              'MENOS'),\n",
        "        ('\\*',              'MULTIPLICAR'),\n",
        "        ('\\/',              'DIVIDIR'),\n",
        "        ('\\(',              'PIZQ'),\n",
        "        ('\\)',              'PDER'),\n",
        "        (':=',              'ASIGNAR'),\n",
        "    ]\n",
        "\n",
        "    #Creamos una instancia de un lexer\n",
        "    lx = Lexer(reglas, skip_whitespace=True)\n",
        "    #Ejemplos / casos de entradas\n",
        "    lx.input('ab := (s1 + b2) / (-1.2*A1*C1)')\n",
        "    #lx.input('12.4')\n",
        "    #lx.input('ar := seno(20) + 56 * AB')\n",
        "    #lx.input('rw*9')\n",
        "    #lx.input('miformula := seno(10 * seno(15 + AB))');\n",
        "\n",
        "    try:\n",
        "        for tok in lx.tokens():\n",
        "            print(tok)\n",
        "    except LexerError as err:\n",
        "        print('Ha ocurrido un error en la posición: %s' % err.pos)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconocido: (?P<GROUP1>[+-]?\\d+(\\.\\d+)?)\n",
            "Reconocido: (?P<GROUP2>[+-]?\\d+)\n",
            "Reconocido: (?P<GROUP3>seno)\n",
            "Reconocido: (?P<GROUP4>[a-zA-Z_]\\w+)\n",
            "Reconocido: (?P<GROUP5>\\+)\n",
            "Reconocido: (?P<GROUP6>\\-)\n",
            "Reconocido: (?P<GROUP7>\\*)\n",
            "Reconocido: (?P<GROUP8>\\/)\n",
            "Reconocido: (?P<GROUP9>\\()\n",
            "Reconocido: (?P<GROUP10>\\))\n",
            "Reconocido: (?P<GROUP11>:=)\n",
            "\n",
            "Grupos Reconocidos: {'GROUP1': 'NUMERODECIMAL', 'GROUP2': 'NUMEROENTERO', 'GROUP3': 'FNSENO', 'GROUP4': 'IDENTIFICADOR', 'GROUP5': 'MAS', 'GROUP6': 'MENOS', 'GROUP7': 'MULTIPLICAR', 'GROUP8': 'DIVIDIR', 'GROUP9': 'PIZQ', 'GROUP10': 'PDER', 'GROUP11': 'ASIGNAR'}\n",
            "\n",
            " Expresión Total: re.compile('(?P<GROUP1>[+-]?\\\\d+(\\\\.\\\\d+)?)|(?P<GROUP2>[+-]?\\\\d+)|(?P<GROUP3>seno)|(?P<GROUP4>[a-zA-Z_]\\\\w+)|(?P<GROUP5>\\\\+)|(?P<GROUP6>\\\\-)|(?P<GROUP7>\\\\*)|(?P<GROUP8>\\\\/)|(?P<GROUP9>\\\\()|(?P<GROUP10>\\\\))|(?P<G)\n",
            "\n",
            "IDENTIFICADOR | ab |-> en la posición: 0\n",
            "ASIGNAR | := |-> en la posición: 3\n",
            "PIZQ | ( |-> en la posición: 6\n",
            "IDENTIFICADOR | s1 |-> en la posición: 7\n",
            "MAS | + |-> en la posición: 10\n",
            "IDENTIFICADOR | b2 |-> en la posición: 12\n",
            "PDER | ) |-> en la posición: 14\n",
            "DIVIDIR | / |-> en la posición: 16\n",
            "PIZQ | ( |-> en la posición: 18\n",
            "NUMERODECIMAL | -1.2 |-> en la posición: 19\n",
            "MULTIPLICAR | * |-> en la posición: 23\n",
            "IDENTIFICADOR | A1 |-> en la posición: 24\n",
            "MULTIPLICAR | * |-> en la posición: 26\n",
            "IDENTIFICADOR | C1 |-> en la posición: 27\n",
            "PDER | ) |-> en la posición: 29\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}